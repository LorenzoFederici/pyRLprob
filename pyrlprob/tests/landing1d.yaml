run: ppo
stop:
  training_iteration: 100
custom_metrics: [cstr_viol]
postproc:
  episode_step_data: [h, v, m, t, T]
config:
  num_workers: 2
  num_envs_per_worker: 5
  num_gpus: 0
  num_cpus_per_worker: 1
  num_gpus_per_worker: 0
  num_cpus_for_driver: 1
  rollout_fragment_length: 75
  batch_mode: complete_episodes
  model:
    fcnet_hiddens: [64, 64]
    fcnet_activation: tanh
    vf_share_layers: False
    free_log_std: True
  gamma: 1.
  log_level: INFO
  framework: tf
  explore: True
  ignore_worker_failures: True
  evaluation_interval: 1
  evaluation_num_episodes: 1
  evaluation_config:
    explore: False
    env_config:
      prng_seed: 0
  evaluation_num_workers: 0
  use_critic: True
  use_gae: True
  lambda: 1.
  kl_coeff: 0.
  sgd_minibatch_size: 150
  shuffle_sequences: True
  num_sgd_iter: 20
  lr: 5.0e-04
  vf_loss_coeff: 0.5
  clip_param: 0.15
  callbacks:
    TrainingCallbacks
  env: Landing1DEnv
  env_config:
    H: 15
    h0: 1.0
    v0: -0.783
    m0: 1.0
    tf: 1.397
    hf: 0.0
    vf: 0.0
    Tmax: 1.227
    c: 2.349
    g: 1.0